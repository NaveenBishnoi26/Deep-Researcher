import openai
#from openai import Client
from openai import OpenAIError
from dotenv import load_dotenv
import os
load_dotenv()
#client=Client()

def grade_report(topic, report):
    openai.api_key = "OPENAI_API_KEY"

    prompt = f"""
    {topic}
    {report}

    You are a trained evaluator in academic research methodology, factual verification, and technical depth. You are comparing multiple reports generated by AI research agents in response to the same research question. Your evaluation must be **evidence-based, and precise**.

        Your goal is not to be too generous. Even good reports must earn their score through **clear demonstration** of quality in each of the following five dimensions:

        1. **Factual Accuracy (2 pts)**  
        - 2: No hallucinations. All claims are clearly verifiable with evidence or citations.  
        - 1: One or two minor unsupported claims, or generalizations without clear evidence.  
        - 0: Major factual errors, hallucinated references, or unverifiable claims.  

        2. **Depth of Analysis (2 pts)**  
        - 2: Demonstrates deep insight into causes, mechanisms, trade-offs, or implications.  
        - 1: Some analysis beyond surface-level, but lacks depth or misses key insights.  
        - 0: Mostly descriptive or summary-like with no real analytical value.  

        3. **Relevance & Focus (2 pts)**  
        - 2: Fully aligned with the research question; no digressions or filler.  
        - 1: Mostly focused, but contains small irrelevant portions or vague sections.  
        - 0: Strays too much from topic or includes significant off-topic content.  

        4. **Language & Structure (2 pts)**  
        - 2: Clear, concise, and logically structured; reads like a publishable abstract.  
        - 1: Understandable but includes awkward phrasing, unclear transitions, or minor structural flaws.  
        - 0: Disorganized, hard to follow, or grammatically weak.  

        5. **Use of Evidence & References (2 pts)**  
        - 2: Uses multiple real, relevant, and recent sources that are smoothly integrated.  
        - 1: Mentions a few sources or vaguely refers to evidence but lacks integration.  
        - 0: No real sources used, or references are fabricated, outdated, or irrelevant. 

        ---

        ### Output Format (for each pdf):
        
        Model:  
        Score:  
        Justification:

    """

    score_prompt = prompt + """
    Give a score from 0-10 based on the grading criteria. **Scores (out of 10):**  
    - Factual Accuracy: X/2  
    - Depth of Analysis: X/2  
    - Relevance & Focus: X/2  
    - Language & Structure: X/2  
    - Evidence & References: X/2  

    **Total Score: X/10**
    """
    justification_prompt = prompt + """
    Only return justification for the score. **Justification:**
    Factual Accuracy: [...]  
    Depth of Analysis: [...]  
    Relevance & Focus: [...]  
    Language & Structure: [...]  
    Evidence & References: [...]
    """

    scoreNjustification = [0,0]

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": score_prompt}],
            temperature=0.0
        )
        scoreNjustification[0] = str(response['choices'][0]['message']['content'].strip())
    except OpenAIError as e:
        return ("e","e")  # Could not grade
    

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": justification_prompt}],
            temperature=0.0
        )
        scoreNjustification[1] = response['choices'][0]['message']['content'].strip()
    except OpenAIError as e:
        return ("e","e")  # Could not grade

    return scoreNjustification  